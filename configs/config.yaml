project:
  name: "ParaDetect"
  version: "1.0.0"
  environment: "development"  # development, staging, production

data:
  raw_data_dir: "data/raw/"
  processed_data_dir: "data/processed/"
  interim_data_dir: "data/interim/"

# Data Ingestion Configuration
data_ingestion:
  dataset_name: "artem9k/ai-text-detection-pile"
  source_type: "huggingface"  # huggingface, local, url
  raw_data_dir: "data/raw/"
  dataset_filename: "ai_text_detection_pile.csv"
  sample_size: 10000  # For development/testing, use a smaller sample
  random_state: 42

# Data Preprocessing Configuration
data_preprocessing:
  text_column: "text"
  label_column: "generated"
  source_column: "source"
  remove_duplicates: true
  min_text_length: 50
  max_text_length: 5000
  lowercase: false
  strip_whitespace: true
  remove_special_chars: false
  balance_classes: true
  processed_data_dir: "data/processed/"
  processed_filename: "ai_text_detection_pile_processed.csv"
  random_state: 42

# Data Validation Configuration
data_validation:
  expected_columns: ["text", "generated", "source"]
  required_columns: ["text", "generated"]
  text_column: "text"
  label_column: "generated"
  min_text_length: 10
  max_text_length: 10000
  expected_labels: [0, 1]
  min_samples_per_class: 100
  max_null_percentage: 0.05
  validation_report_dir: "artifacts/reports/"
  report_filename: "data_validation_report.json"

# Pipeline Configuration - State Management
pipeline:
  artifacts_dir: "artifacts/"
  checkpoints_dir: "artifacts/checkpoints/"
  state_files:
    data_pipeline: "artifacts/states/data_pipeline_state.json"
    training_pipeline: "artifacts/states/training_pipeline_state.json"
    inference_pipeline: "artifacts/states/inference_pipeline_state.json"
    monitoring_pipeline: "artifacts/states/monitoring_pipeline_state.json"
    deployment_pipeline: "artifacts/states/deployment_pipeline_state.json"
  enable_state_persistence: true
  state_auto_save: true
  state_retention_days: 30
  enable_pipeline_locks: true

# Inference Configuration
inference:
  # Model configuration
  model_path: null  # Path to trained model, null for latest
  tokenizer_path: null  # Path to tokenizer, null to use model_path
  device_preference: "auto"  # auto, cuda, mps, cpu

  # Inference parameters
  batch_size: 32
  max_length: 512

  # Processing configuration
  text_column: "text"
  preprocessing_enabled: true

  # Output configuration
  include_probabilities: true
  include_confidence: true
  confidence_threshold: 0.5

  # Monitoring configuration
  enable_monitoring: true
  log_predictions: false  # For privacy, default to False

  # Batch processing configuration
  chunk_size: 1000  # For large batch processing
  progress_bar: true

  # Error handling
  skip_errors: true
  max_retries: 3

  # API configuration
  api:
    host: "0.0.0.0"
    port: 8000
    workers: 1
    reload: false

# Logging Configuration
logging:
  level: "INFO"
  format: "%(asctime)s [%(levelname)s] %(name)s (%(filename)s:%(lineno)d) - %(message)s"
  log_dir: "artifacts/logs/"

  # Component-specific logging
  loggers:
    data_pipeline:
      level: "INFO"
      handlers: ["console", "main_file"]
      propagate: false
    training_pipeline:
      level: "INFO"
      handlers: ["console", "main_file"]
      propagate: false
    inference_pipeline:
      level: "INFO"
      handlers: ["console", "main_file"]
      propagate: false
    model_training:
      level: "DEBUG"
      handlers: ["console", "main_file", "debug_file"]
      propagate: false

  # Enhanced log rotation with date-based naming
  rotation:
    when: "midnight"           # midnight, H, D, W0-W6
    interval: 1                # Rotate every interval
    backup_count: 7            # Keep 7 days of logs
    compress: true             # Compress old logs
    retention_days: 30         # Clean up logs older than 30 days

  # Structured logging for production
  structured: false            # Enable for production
  json_format: false          # Enable for production

# Monitoring Configuration
monitoring:
  enable: true
  metrics_dir: "artifacts/metrics/"
  track_data_drift: true
  track_model_performance: true

# Environment-specific overrides
environments:
  development:
    data_ingestion:
      sample_size: 1000  # Smaller sample for development
    logging:
      level: "DEBUG"
      rotation:
        backup_count: 3
        retention_days: 7

  staging:
    data_ingestion:
      sample_size: 50000
    logging:
      level: "INFO"
      structured: true
      rotation:
        backup_count: 14
        retention_days: 30

  production:
    data_ingestion:
      sample_size: null  # Full dataset
    logging:
      level: "WARNING"
      structured: true
      json_format: true
      rotation:
        backup_count: 30
        retention_days: 90
        compress: true
    inference:
      log_predictions: false
      enable_monitoring: true
